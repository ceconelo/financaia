import { GoogleGenerativeAI } from '@google/generative-ai';
import OpenAI from 'openai';
import 'dotenv/config';
import fs from 'fs';
import path from 'path';
import os from 'os';

// ============ CONFIGURATION ============

const AI_PROVIDER = (process.env.AI_PROVIDER || 'gemini').toLowerCase();

// Clients
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');
const geminiModel = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || '',
});

// ============ CONSTANTS & PROMPTS ============

export interface TransactionData {
  amount: number;
  category: string;
  type: 'INCOME' | 'EXPENSE';
  description?: string;
}

const CATEGORIES = {
  'renda': 'Sal√°rio, freelance, vendas, restitui√ß√µes, dividendos ou qualquer entrada de dinheiro.',
  'gastos essenciais': 'Moradia (aluguel, condom√≠nio), contas (luz, √°gua, internet), mercado, farm√°cia, transporte obrigat√≥rio (combust√≠vel trabalho, √¥nibus).',
  'estilo de vida': 'Lazer, comer fora, restaurantes, iFood, bares, cinema, viagens, compras pessoais, streaming, academia.',
  'poupan√ßa': 'Investimentos, reserva de emerg√™ncia, aplica√ß√µes financeiras.',
  'estudos': 'Faculdade, cursos, livros, material escolar, idiomas.',
  'doa√ß√£o': 'Caridade, d√≠zimo, ajuda a terceiros, presentes.'
};

const JSON_FORMAT = `{
  "amount": number,
  "type": "INCOME" | "EXPENSE",
  "category": "string (one of the allowed categories)",
  "description": "string"
}`;

function buildTransactionPrompt(userInput: string): string {
  const categoriesList = Object.entries(CATEGORIES)
    .map(([cat, desc]) => `- "${cat}": ${desc}`)
    .join('\n');

  return `Voc√™ √© um assistente financeiro especialista em categoriza√ß√£o de gastos brasileiros.
Analise a seguinte mensagem e extraia os dados financeiros com precis√£o.

CATEGORIAS PERMITIDAS (Use EXATAMENTE um destes nomes):
${categoriesList}

REGRAS:
1. Responda APENAS com um JSON v√°lido no formato:
${JSON_FORMAT}
2. O campo "amount" deve ser um n√∫mero puro (ex: 50.50), sem s√≠mbolos de moeda.
3. Se for entrada de dinheiro, type="INCOME". Se for sa√≠da, type="EXPENSE".
4. Se n√£o identificar valor financeiro, retorne: { "error": "N√£o identifiquei um gasto ou receita v√°lido" }

Mensagem do usu√°rio: "${userInput}"`;
}

function buildReceiptPrompt(): string {
  const categoriesList = Object.entries(CATEGORIES)
    .map(([cat, desc]) => `- "${cat}": ${desc}`)
    .join('\n');

  return `Analise esta imagem de nota fiscal ou comprovante e extraia os dados.

CATEGORIAS PERMITIDAS:
${categoriesList}

Responda APENAS com JSON no formato:
${JSON_FORMAT}

Se n√£o for poss√≠vel ler, retorne erro.`;
}

// ============ HELPERS ============

function parseResponse(responseText: string): TransactionData | null {
  try {
    const jsonMatch = responseText.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.warn('AI Response did not contain JSON:', responseText);
      return null;
    }

    const data = JSON.parse(jsonMatch[0]);

    if (data.error) return null;

    return {
      amount: parseFloat(data.amount),
      type: data.type,
      category: data.category?.toLowerCase() || 'outros',
      description: data.description
    };
  } catch (e) {
    console.error('Error parsing AI response:', e);
    return null;
  }
}

// ============ GEMINI IMPLEMENTATION ============

async function parseTransactionGemini(text: string): Promise<TransactionData | null> {
  try {
    const prompt = buildTransactionPrompt(text);
    const result = await geminiModel.generateContent(prompt);
    return parseResponse(result.response.text());
  } catch (error) {
    console.error('Gemini Parse Error:', error);
    return null;
  }
}

async function transcribeAudioGemini(audioBuffer: Buffer): Promise<string | null> {
  try {
    const audioPart = {
      inlineData: {
        data: audioBuffer.toString('base64'),
        mimeType: 'audio/ogg; codecs=opus',
      },
    };
    const result = await geminiModel.generateContent(['Transcreva este √°udio em portugu√™s do Brasil, mantendo os valores num√©ricos exatos:', audioPart]);
    return result.response.text().trim();
  } catch (error) {
    console.error('Gemini Transcription Error:', error);
    return null;
  }
}

async function analyzeReceiptGemini(imageBuffer: Buffer): Promise<TransactionData | null> {
  try {
    const imagePart = {
      inlineData: {
        data: imageBuffer.toString('base64'),
        mimeType: 'image/jpeg',
      },
    };
    const prompt = buildReceiptPrompt();
    const result = await geminiModel.generateContent([prompt, imagePart]);
    return parseResponse(result.response.text());
  } catch (error) {
    console.error('Gemini Receipt Error:', error);
    return null;
  }
}

// ============ OPENAI IMPLEMENTATION ============

async function parseTransactionOpenAI(text: string): Promise<TransactionData | null> {
  try {
    const prompt = buildTransactionPrompt(text);
    const completion = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
      messages: [{ role: 'user', content: prompt }],
      response_format: { type: 'json_object' },
      temperature: 0.1,
    });
    return parseResponse(completion.choices[0].message.content || '');
  } catch (error) {
    console.error('OpenAI Parse Error:', error);
    return null;
  }
}

async function transcribeAudioOpenAI(audioBuffer: Buffer): Promise<string | null> {
  try {
    const tempFilePath = path.join(os.tmpdir(), `audio_${Date.now()}.ogg`);
    fs.writeFileSync(tempFilePath, audioBuffer);
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(tempFilePath),
      model: 'whisper-1',
      language: 'pt',
    });
    fs.unlinkSync(tempFilePath);
    return transcription.text;
  } catch (error) {
    console.error('OpenAI Transcription Error:', error);
    return null;
  }
}

async function analyzeReceiptOpenAI(imageBuffer: Buffer): Promise<TransactionData | null> {
  try {
    const base64Image = imageBuffer.toString('base64');
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: buildReceiptPrompt() },
            { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${base64Image}` } }
          ]
        }
      ],
      response_format: { type: 'json_object' },
      temperature: 0.2, // Lower temperature for extraction tasks
    });
    return parseResponse(completion.choices[0].message.content || '');
  } catch (error) {
    console.error('OpenAI Receipt Error:', error);
    return null;
  }
}

// ============ PUBLIC API ============

export async function parseTransaction(text: string): Promise<TransactionData | null> {
  console.log(`ü§ñ AI Provider: ${AI_PROVIDER.toUpperCase()}`);
  return AI_PROVIDER === 'openai' ? parseTransactionOpenAI(text) : parseTransactionGemini(text);
}

export async function transcribeAudio(audioBuffer: Buffer): Promise<string | null> {
  return AI_PROVIDER === 'openai' ? transcribeAudioOpenAI(audioBuffer) : transcribeAudioGemini(audioBuffer);
}

export async function analyzeReceipt(imageBuffer: Buffer): Promise<TransactionData | null> {
  return AI_PROVIDER === 'openai' ? analyzeReceiptOpenAI(imageBuffer) : analyzeReceiptGemini(imageBuffer);
}
